{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from src.datamodules.focus_datamodule import FocusDataModule\n",
    "from src.models.focus_module import FocusModule\n",
    "from src.models.components.mobile_net_v3 import MobileNetV3\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"/home/maf4031/focus_model/logs/train/runs/2022-12-13_00-53-11/checkpoints/epoch_082.ckpt\"\n",
    "# load model checkpoint\n",
    "checkpoint = torch.load(path_to_model, map_location=torch.device('cpu'))\n",
    "state_dict = checkpoint['state_dict']\n",
    "# remove net in keys from state_dict\n",
    "state_dict = {k.replace(\"net.\", \"\"): v for k, v in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV3()\n",
    "_ = model.load_state_dict(state_dict)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 20\n",
    "path_to_img = f\"/n/data2/hms/dbmi/kyu/lab/maf4031/focus_dataset/Inflammation_5/sample_34/distance{distance}.jpg\"\n",
    "img = io.imread(path_to_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = img.shape[:2]\n",
    "w_scaled = int(w * 0.3)\n",
    "h_scaled = int(h * 0.3)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(), \n",
    "            transforms.Resize(size=(h_scaled, w_scaled), interpolation=InterpolationMode.BILINEAR),\n",
    "            transforms.Normalize((0), (1)),\n",
    "        ])\n",
    "img_torch = transform(img)\n",
    "img_torch = img_torch.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[79.1017]])\n",
      "68.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(img_torch)\n",
    "print(output)\n",
    "print(distance*3.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datamodules.components.focus_dataset import FocusDataset\n",
    "d = torch.load(\"/home/maf4031/focus_model/data/datasets/dataset_subsample100_grid.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "focus-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33478f73054285d77182a29c6ac236a6b8fbd6e41560db5562e9a00546556004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
